#!/bin/bash

# This bash script wraps the functionalities of web_crawler.py

me=$(basename $0)
binpath=$(dirname $0)
script=project/web_crawler.py

# Exit codes
OK=0
FAIL=1

# Usage functions
function synopsis {
    synopsis=$(python $script 2>&1 | head -1 | sed -e 's/usage: \(.*\)/\1/')
    synopsis=${synopsis/.py/}
    echo $synopsis
}

function get_options {
	pos_args="positional arguments"
	opt_args="optional arguments"
    export pattern_one=$pos_args
    export pattern_two=$opt_args
	usage_txt=$(python $script --help)

    # Get positional arguments
    script="$(cat <<"EOF"
    # Get each option
    if ((/$ENV{pattern_one}/../$ENV{pattern_two}/) &&    # Print anything between
        !(/$ENV{pattern_one}/||/$ENV{pattern_two}/)) {   # the two patterns
        $opt = $_;
    }
    if ($opt =~ /^\s{3,}/) {
        # Remove traling or leading spaces
        $opt =~ s/^\s+|\s+\n$//g;
        print("\t" x 4 . $opt);
    }
    elsif ($opt =~ /^\s+/) {
        # Remove traling or leading spaces
        $opt =~ s/^\s+|\s+\n$//g;
        # Add double hypen for positional arguments
        $opt =~ s/^(.+)$/--$1/;
        # Readjust the spacing
        $opt =~ s/\s{2,}/\t\t/;
        if ($opt =~ /--.{1,5}\t/) {
            $opt =~ s/(.+)\t/$1\t\t/;
        }
        if ($opt) {
            print("$opt");
        }
    }
EOF
)"
	echo "$usage_txt" | perl -ne "$script"

    # Get optional arguments
    script="$(cat <<"EOF"
    my $pad = " " x 4;

    if ($can_print) {
        my $opt = $_;
        # Remove traling or leading spaces
        $opt =~ s/^[\s\t]+|[\s\t]+$//g;
        # Multiline comment
        if ($_ =~ /^\s+[a-zA-Z]+/) {
            if ($_ !~ /^\s+$/) {
                if ($no_pad eq 1) {
                    if ($prev) {
                        printf("\n${prev}\t\t%s\n", $opt);
                        $prev = "";
                    }
                    $no_pad = 0;
                }
                else {
                    printf("%s$opt\n", $pad x 8);
                }
            }
            next;
        }
        else {

            # Readjust the spacing
            $opt =~ s/(.+)(\s{2,})/$1\t\t/;

            # Add padding
            $opt =~ s/^(.+)$/${pad}${1}/;

            $no_pad = 0;

            if ($opt =~ /\t[\w\d]+/) {
                # Add newline
                if ($opt !~ /\n$/) {
                    $opt =~ s/^(.+)$/$1\n/;
                }
                if ($opt !~ /^\s+$/) {
                    print("\n$opt");
                }
            }
            else {
                $no_pad = 1;
                $prev = $opt;
            }
        }
    }
    if (/$ENV{pattern_two}/) {
        $can_print = 1;
    }
EOF
)"
    echo "$usage_txt" | perl -ne "$script"
}

function get_version {
    version="$(python $script --version 2>&1)"
    echo ${version/.py/}
}

function usage {
    bold=$(tput bold)
    underline=$(tput smul)
    reset=$(tput sgr0)
    # redirect usage >&2
	cat <<-END
${bold}NAME${reset}

    ${me} -- networks' international calling costs web crawler

${bold}SYNOPSIS${reset}

    $(synopsis)

    (See the OPTIONS section for alternate option syntax with long option names.)

${bold}DESCRIPTION${reset}

    ${underline}${me}${reset} is a simple web crawler for networks’ international calling costs.

    The script queries a network’s website directly to obtain a list of calling costs.
    These costs are: based on country zones, per minute and only related to calls to
    a foreign country from the UK.

    ${underline}${me}${reset} requires a JSON file containing:
        - operator name
        - operator URL
        - list of country zones
        - list of actions for the Selenium driver
        - load time: the maximum amount of time to wait for a page element to get loaded
        - sleep time: the amount of time of sleeping after each action

    A log file can be used to track the crawling process, if not supplied then all the
    messages will be printed to STDOUT (default).

${bold}OPTIONS${reset}

    $(get_options)

${bold}EXAMPLES${reset}

    Run with logging at debug level, printing to STDOUT:

        web_crawler --data ../data/sites/operators.json -l "debug"

    Print the output to STDOUT in JSON format:

        web_crawler --data ../data/sites/operators.json --json

    Print the output to a file in JSON format:

        web_crawler --data ../data/sites/operators.json --json --out file.json

    Log the process to a specific directory:

        web_crawler --data ../data/sites/operators.json --lod-dir /var/log/


${bold}REQUIREMENTS${reset}

    Python modules: argparse, coloredlog, chromedriver, selenium

${bold}EXIT CODES${reset}

    0 - Success
    1 - Failure

${bold}AUTHOR${reset}

    Luigi Riefolo <luigi.riefolo@gmail.com>

${bold}LICENSE${reset}

    This script is in the public domain, free from copyrights or restrictions.

${bold}VERSION${reset}

    $(get_version)

END
}


# Script invoked with no command-line args

if [[ $# == 0 ]]
then
	usage
	exit $E_OPTERROR
fi

optspec=":hv-:"
while getopts "$optspec" optchar; do
    case "${optchar}" in
        h)
            usage
            exit $OK
            ;;
        *)
            if [ "$OPTERR" != 1 ] || [ "${optspec:0:1}" = ":" ]; then
                echo "Non-option argument: '-${OPTARG}'" >&2
            fi
            ;;
    esac
done

python "$binpath/../$script" $@
ret=$?
if [[ $ret -ne 0 ]];
then
    echo "See the usage: web_crawler -h"
fi
